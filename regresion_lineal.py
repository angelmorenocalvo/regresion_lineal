# -*- coding: utf-8 -*-
"""Regresion_lineal.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I-9JmpZ7C_uM-GC1d5GO8ZeUsVUSEPb2
"""

import numpy as np
import matplotlib.pyplot as plt

# Cogemos de la libreria sklearn los datos de boston
from sklearn.datasets import load_boston

# Cargamos la libreria
boston = load_boston()
print(boston.DESCR)

"""Formula para minimizar el error cuadratico medio en dos dimensiones: $\beta = (X^{t} X)^{-1}X^{t}Y$"""

# Cogemos el numero de hogares por cada barrio
#x = boston.data[:,5]
# Coste de las viviendas
#y = boston.target

# ahora pasamos los datos a matrices
X = np.array(boston.data[:,5])
Y = np.array(boston.target)

# Para realizar la gráfica lo que es necesiario es la libreria matplot
plt.scatter(X,Y, alpha = 0.3) # con alpha hacemos que los 
#puntos sean algo transparentes
#plt.show()

# Añadimos una columna de 1 que representan el termino independiente
X = np.array([np.ones(506),X]).T # Donde 506 es el numero de filas

# No se puede graficar ahora porque tenemos un array de distintas dimensiones

B = np.linalg.inv(X.T @ X) @ X.T @ Y# Con x.T se obtiene la transpuesta de T
# Para hacer la multiplicación matricial utilizamos @
# Para calcular la inversa nos vamos al paquete de algebra lineal de np
plt.plot([4,9],[B[0]+B[1]*4, B[0]+B[1]*9], c ="red")
plt.show()

B # Aqui contamos con el parametro independiente y la pendiente